{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d41b980",
   "metadata": {},
   "source": [
    "# Using fhir-query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b05ce3",
   "metadata": {},
   "source": [
    "## fq (fhir-query): Your FHIR Querying Assistant\n",
    "The fq utility, short for \"fhir-query,\" is a command-line tool specifically designed to simplify the process of interacting with FHIR servers. It provides researchers with a convenient way to:\n",
    "\n",
    "1. Retrieve the vocabulary of a FHIR server: With the vocabulary command, fq fetches and summarizes the key data elements (CodeableConcepts and Extensions) used within the FHIR data. This creates a central vocabulary Dataframe that helps researchers identify important data elements and their usage within the server.\n",
    "\n",
    "\n",
    "2. Execute queries to retrieve FHIR resources: Researchers can then use fq to execute FHIR queries using a readable syntax. This helps to retrieve and filter data from the FHIR Server based on various search parameters and criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d402b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fhir-aggregator-client==0.1.8 --no-cache-dir --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2138ba",
   "metadata": {},
   "source": [
    "### Verify installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1e35f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: fq [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  FHIR-Aggregator utilities.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  ls          List all the installed GraphDefinitions.\n",
      "  run         Run GraphDefinition queries.\n",
      "  results     Work with the results of a GraphDefinition query.\n",
      "  vocabulary  FHIR-Aggregator's key Resources and CodeSystems.\n"
     ]
    }
   ],
   "source": [
    "!fq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570622ec",
   "metadata": {},
   "source": [
    "### Overview  \n",
    "\n",
    "This notebook leverages **[FHIR GraphDefinition](https://hl7.org/fhir/graphdefinition.html)** objects to define and execute graph-based traversals across multiple interconnected FHIR resource graphs. The data retrieved is written to a **local SQLite database** for persistence and later transformed into **analyst-friendly dataframes** for analysis using tools like Python’s pandas library.\n",
    "\n",
    "By using **FHIR GraphDefinition**, we declaratively define resource relationships and efficiently retrieve data. Once retrieved, the data is stored locally and can be transformed into dataframes for advanced analysis.\n",
    "\n",
    "The [fhir-aggregator-client](https://github.com/FHIR-Aggregator/fhir-aggregator-client) tool runs an R5 GraphDefinition against a FHIR server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc341858-80cf-424d-9316-42a4a9d69bd2",
   "metadata": {},
   "source": [
    "### Key Features  \n",
    "\n",
    "- **GraphDefinition-Driven Traversals**: Use GraphDefinition objects to define explicit relationships between resources and automate traversal logic.  \n",
    "- **Local SQLite Storage**: Persist the retrieved FHIR data in a local SQLite database for querying and offline analysis.  \n",
    "- **Analyst-Friendly Dataframes**: Convert stored FHIR resources into pandas dataframes for ease of use in analytical workflows.  \n",
    "- **Reusable Graph Definitions**: Maintain a library of GraphDefinition YAML files that can be reused across different workflows and projects.  Researchers and Data submitters can publish GraphDefinition files to help others navigate their data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b7bb5",
   "metadata": {},
   "source": [
    "### List installed GraphDefinition files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b368aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| id                          | description                                                                                                                             |\n",
      "|-----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| condition-graph             | (FHIR-Aggregator) Condition to ResearchStudy and children. fhir-query '/Condition?code:text=cholangiocarcinoma'                         |\n",
      "| patient-survival-graph      | (FHIR-Aggregator) Retrieve Patient and Observations [NCIT_C156418,NCIT_C156419]. fhir-query '/ResearchStudy?identifier=TCGA-BRCA'       |\n",
      "| research-study-link-iterate | (dbGAP) Retrieve ResearchStudy and children. Uses HAPI's deep linking. fhir-query '/ResearchStudy?_id=phs001232'                        |\n",
      "| research-study-part-of      | (FHIR-Aggregator) Retrieve a ResearchStudy and children. Uses part-of-study extension. fhir-query '/ResearchStudy?identifier=TCGA-BRCA' |\n"
     ]
    }
   ],
   "source": [
    "!fq ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026d28d",
   "metadata": {},
   "source": [
    "### Run a GraphDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bebb134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FHIR_BASE=https://google-fhir.fhir-aggregator.org\n"
     ]
    }
   ],
   "source": [
    "%env FHIR_BASE= https://google-fhir.fhir-aggregator.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57469855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: Database already exists at C:\\Users\\Parker.Gray\\.fhir-aggregator\\fhir-graph.sqlite and will be used. If this is not what you intended, please remove the existing database or provide a new path.\n",
      "condition-graph is valid FHIR R5 GraphDefinition\n",
      "\n",
      "¡ Fetching https://google-fhir.fhir-aggregator.org/Condition?code:text=cholangiocarcinoma\n",
      "\n",
      "Error: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!fq run condition-graph /Condition?code:text=cholangiocarcinoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f336e",
   "metadata": {},
   "source": [
    "#### Analyse Results\n",
    "\n",
    "The graph represents relationships between different FHIR resources.Examples of FHIR resources include Patient, Condition, Observation, Procedure, etc.\n",
    "\n",
    "Each node is labled as: <resource_type\\>/<count\\> the number of records of that type retrieved.\n",
    "\n",
    "The edges in the graph are weighted.  The thicker the line, the more connections there are between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5a4b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error: 'charmap' codec can't encode characters in position 263607-263621: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Parker.Gray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fhir_aggregator_client\\cli.py\", line 273, in visualize\n",
      "    visualize_aggregation(db.aggregate(ignored_edges), output_path.name)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Parker.Gray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fhir_aggregator_client\\visualizer.py\", line 34, in visualize_aggregation\n",
      "    net.save_graph(str(output_path))\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Parker.Gray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyvis\\network.py\", line 438, in save_graph\n",
      "    self.write_html(name)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\Parker.Gray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyvis\\network.py\", line 530, in write_html\n",
      "    out.write(self.html)\n",
      "    ~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Parker.Gray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 263607-263621: character maps to <undefined>\n",
      "Error: 'charmap' codec can't encode characters in position 263607-263621: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "# Create a graph of the results\n",
    "!fq results visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12238bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='height: 800px;'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the locally stored HTML file containing a graph visualization and displaying it within the Jupyter notebook.\n",
    "\n",
    "from IPython.display import HTML\n",
    "with open('fhir-graph.html', 'r') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Set the display height (in pixels)\n",
    "display(HTML(\"<div style='height: 800px;'>{}</div>\".format(html_content)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345a16d",
   "metadata": {},
   "source": [
    "#### Create a dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56051779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved fhir-graph.tsv\n"
     ]
    }
   ],
   "source": [
    "!fq results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6862c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfhir-graph.tsv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('fhir-graph.tsv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d44d0",
   "metadata": {},
   "source": [
    "### Other servers\n",
    "\n",
    "You can use the `fq` tool with other FHIR servers.  For example, this query retrieves a study from `dbGAP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the previous results, start with a fresh database\n",
    "!rm ~/.fhir-aggregator/fhir-graph.sqlite\n",
    "!fq run  --fhir-base-url https://dbgap-api.ncbi.nlm.nih.gov/fhir-jpa-pilot/x1  research-study-link-iterate  '/ResearchStudy?_id=phs001232'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same commands to analyse results\n",
    "!fq results visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph of the results\n",
    "\n",
    "from IPython.display import HTML\n",
    "with open('fhir-graph.html', 'r') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Set the display height (in pixels)\n",
    "display(HTML(\"<div style='height: 800px;'>{}</div>\".format(html_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d727347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of results\n",
    "!fq results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('fhir-graph.tsv', sep='\\t')\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
